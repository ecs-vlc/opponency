# Spatial and Colour Opponency in Anatomically Constrained Deep Networks

Accepted to the NeurIPS 2019 workshop, [Shared Visual Representations in Humans and Machines (SVRHM)](https://www.svrhm2019.com/)

## Notebooks

<table>
    <tr>
        <td rowspan="2" width="160">
            <img src="https://raw.githubusercontent.com/ecs-vlc/opponency/master/figures/spectrally_opponent.png" width="256">
        </td>    
        <td rowspan="2">
            <b>Spectral Opponency:</b> Generating the spectral opponency figures from the paper.
        </td>
        <td align="center" width="80">
            <a href="https://nbviewer.jupyter.org/github/ecs-vlc/opponency/blob/master/spectral_opponency.ipynb">
                <img src="http://www.pytorchbearer.org/assets/img/nbviewer_logo.svg" height="34">
            </a>
        </td>
    </tr>
    <tr>
        <td align="center">
            <a href="https://github.com/ecs-vlc/opponency/blob/master/spectral_opponency.ipynb">
                <img src="http://www.pytorchbearer.org/assets/img/github_logo.png" height="32">
            </a>
        </td>
    </tr>
<!--     <tr>
        <td align="center">
            <a href="https://colab.research.google.com/github/pytorchbearer/torchbearer/blob/master/docs/_static/notebooks/basic_opt.ipynb">
                <img src="http://www.pytorchbearer.org/assets/img/colab_logo.png" height="28">
            </a>
        </td>
    </tr> -->
    <tr>
        <td rowspan="2">
            <img src="https://raw.githubusercontent.com/ecs-vlc/opponency/master/figures/spatially_opponent.png" width="256">
        </td>    
        <td rowspan="2">
            <b>Spatial Opponency:</b> Generating the spatial opponency figures from the paper.
        </td>
        <td align="center">
            <a href="https://nbviewer.jupyter.org/github/ecs-vlc/opponency/blob/master/spatial_opponency.ipynb">
                <img src="http://www.pytorchbearer.org/assets/img/nbviewer_logo.svg" height="34">
            </a>
        </td>
    </tr>
    <tr>
        <td align="center">
            <a href="https://github.com/ecs-vlc/opponency/blob/master/spatial_opponency.ipynb">
                <img src="http://www.pytorchbearer.org/assets/img/github_logo.png" height="32">
            </a>
        </td>
    </tr>
<!--     <tr>
        <td align="center">
            <a href="https://colab.research.google.com/github/pytorchbearer/torchbearer/blob/master/docs/_static/notebooks/svm_linear.ipynb">
                <img src="http://www.pytorchbearer.org/assets/img/colab_logo.png" height="28">
            </a>
        </td>
    </tr> -->
<!--     <tr>
        <td rowspan="2">
            <img src="http://www.pytorchbearer.org/assets/img/examples/amsgrad.jpg" width="256">
        </td>    
        <td rowspan="2">
            <b>Breaking Adam:</b> The Adam optimiser doesn't always converge, in this example we reimplement some of the function optimisations from the AMSGrad paper showing this empirically.
        </td>
        <td align="center">
            <a href="https://nbviewer.jupyter.org/github/pytorchbearer/torchbearer/blob/master/docs/_static/notebooks/amsgrad.ipynb">
                <img src="http://www.pytorchbearer.org/assets/img/nbviewer_logo.svg" height="34">
            </a>
        </td>
    </tr>
    <tr>
        <td align="center">
            <a href="https://github.com/pytorchbearer/torchbearer/blob/master/docs/_static/notebooks/amsgrad.ipynb">
                <img src="http://www.pytorchbearer.org/assets/img/github_logo.png" height="32">
            </a>
        </td>
    </tr> -->
<!--     <tr>
        <td align="center">
            <a href="https://colab.research.google.com/github/pytorchbearer/torchbearer/blob/master/docs/_static/notebooks/amsgrad.ipynb">
                <img src="http://www.pytorchbearer.org/assets/img/colab_logo.png" height="28">
            </a>
        </td>
    </tr> -->
</table>
